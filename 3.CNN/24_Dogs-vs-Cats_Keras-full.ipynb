{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dogs vs Cats\n",
    "## Kaggle Dataset의 전부를 이용한 개, 고양이 구분\n",
    "### Dog Image: 12,500개, Cat Image: 12,500개, 총 25,000개\n",
    "### 출처: [pontoregende GitHub](https://github.com/pontorezende/Dogs-vs-Cats-Redux-with-CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "import cv2, os, random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='dogs-vs-cats/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## used for resize and in our model\n",
    "ROW, COL = 96, 96\n",
    "\n",
    "dogs, cats = [], []\n",
    "y_dogs, y_cats = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Definition to load all our dog images\n",
    "def load_dogs():\n",
    "    print('Loading all dog images\\n')\n",
    "    dog_path = os.path.join(path, 'dog*')\n",
    "    for dog_img in glob(dog_path):\n",
    "        dog = cv2.imread(dog_img)\n",
    "        dog = cv2.cvtColor(dog, cv2.COLOR_BGR2GRAY)\n",
    "        dog = cv2.resize(dog, (ROW, COL))\n",
    "        dog = image.img_to_array(dog)\n",
    "        dogs.append(dog)\n",
    "    print('All dog images loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Definition to load all our cat images\n",
    "def load_cats():\n",
    "    print('Loading all cat images\\n')\n",
    "    cat_path = os.path.join(path, 'cat*')\n",
    "    for cat_img in glob(cat_path):\n",
    "        cat = cv2.imread(cat_img)\n",
    "        cat = cv2.cvtColor(cat, cv2.COLOR_BGR2GRAY)\n",
    "        cat = cv2.resize(cat, (ROW, COL))\n",
    "        cat = image.img_to_array(cat)\n",
    "        cats.append(cat)\n",
    "    print('All cat images loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all dog images\n",
      "\n",
      "All dog images loaded\n"
     ]
    }
   ],
   "source": [
    "load_dogs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all cat images\n",
      "\n",
      "All cat images loaded\n"
     ]
    }
   ],
   "source": [
    "load_cats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['dog', 'cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## in case we want to see if our images was saved correctly in arrays we can use those codes\n",
    "def show_dogs():\n",
    "    plt.figure(figsize=(12,8))    \n",
    "    for i in range(5):\n",
    "        plt.subplot(1, 5, i+1)\n",
    "        img = image.array_to_img(random.choice(dogs))\n",
    "        plt.imshow(img)\n",
    "        \n",
    "        plt.axis('off')\n",
    "        plt.title('Supposed to be a {}'.format(classes[0]))        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_cats():\n",
    "    plt.figure(figsize=(12,8))\n",
    "    for i in range(5):\n",
    "        plt.subplot(1, 5, i+1)\n",
    "        img = image.array_to_img(random.choice(cats))\n",
    "        plt.imshow(img)\n",
    "\n",
    "        plt.axis('off')\n",
    "        plt.title('Supposed to be a {}'.format(classes[1]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## just change the labels for 0 and  1\n",
    "y_dogs = [1 for item in enumerate(dogs)]\n",
    "y_cats = [0 for item in enumerate(cats)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## converting everything to Numpy array to fit in our model\n",
    "## them creating a X and target file like we used to see\n",
    "## in Machine and Deep Learning models\n",
    "dogs = np.asarray(dogs).astype('float32')\n",
    "cats = np.asarray(cats).astype('float32')\n",
    "y_dogs = np.asarray(y_dogs).astype('int32')\n",
    "y_cats = np.asarray(y_cats).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fit values between 0 and 1\n",
    "dogs /= 255\n",
    "cats /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((dogs,cats), axis=0)\n",
    "y = np.concatenate((y_dogs, y_cats), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_CHANNEL = 1\n",
    "BATCH_SIZE = 128\n",
    "N_EPOCH = 10\n",
    "VERBOSE = 1\n",
    "VALIDAION_SPLIT = .2\n",
    "OPTIM = Adam()\n",
    "N_CLASSES = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## One-Hot Encoding\n",
    "y = tf.keras.utils.to_categorical(y, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 96, 96, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 96, 96, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 48, 48, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 48, 48, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               18874880  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 18,940,898\n",
      "Trainable params: 18,940,898\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Here is our model as a CNN\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), padding='same', input_shape=(ROW, COL, IMG_CHANNEL), activation='relu'),\n",
    "    Conv2D(32, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Dropout(.25),\n",
    "    Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Dropout(.25),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(.5),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIM, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = \"model/dogs_vs_cats-cnn-{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath=modelpath, monitor='val_loss', \n",
    "                               verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "19968/20000 [============================>.] - ETA: 1s - loss: 0.6718 - accuracy: 0.6226\n",
      "Epoch 00001: val_loss improved from inf to 0.63676, saving model to model/dogs_vs_cats-cnn-01-0.6368.hdf5\n",
      "20000/20000 [==============================] - 741s 37ms/sample - loss: 0.6719 - accuracy: 0.6226 - val_loss: 0.6368 - val_accuracy: 0.7058\n",
      "Epoch 2/10\n",
      "19968/20000 [============================>.] - ETA: 1s - loss: 0.5763 - accuracy: 0.6895\n",
      "Epoch 00002: val_loss did not improve from 0.63676\n",
      "20000/20000 [==============================] - 734s 37ms/sample - loss: 0.5762 - accuracy: 0.6896 - val_loss: 0.7543 - val_accuracy: 0.5640\n",
      "Epoch 3/10\n",
      "19968/20000 [============================>.] - ETA: 1s - loss: 0.5124 - accuracy: 0.7492\n",
      "Epoch 00003: val_loss did not improve from 0.63676\n",
      "20000/20000 [==============================] - 732s 37ms/sample - loss: 0.5125 - accuracy: 0.7492 - val_loss: 0.7814 - val_accuracy: 0.5574\n",
      "Epoch 4/10\n",
      "19968/20000 [============================>.] - ETA: 2s - loss: 0.4598 - accuracy: 0.7837 \n",
      "Epoch 00004: val_loss did not improve from 0.63676\n",
      "20000/20000 [==============================] - 1892s 95ms/sample - loss: 0.4598 - accuracy: 0.7836 - val_loss: 0.6408 - val_accuracy: 0.6862\n",
      "Epoch 5/10\n",
      "19968/20000 [============================>.] - ETA: 1s - loss: 0.4092 - accuracy: 0.8157\n",
      "Epoch 00005: val_loss improved from 0.63676 to 0.56838, saving model to model/dogs_vs_cats-cnn-05-0.5684.hdf5\n",
      "20000/20000 [==============================] - 741s 37ms/sample - loss: 0.4090 - accuracy: 0.8159 - val_loss: 0.5684 - val_accuracy: 0.7156\n",
      "Epoch 6/10\n",
      "19968/20000 [============================>.] - ETA: 0s - loss: 0.3670 - accuracy: 0.8375\n",
      "Epoch 00006: val_loss did not improve from 0.56838\n",
      "20000/20000 [==============================] - 609s 30ms/sample - loss: 0.3674 - accuracy: 0.8373 - val_loss: 0.7119 - val_accuracy: 0.6412\n",
      "Epoch 7/10\n",
      "19968/20000 [============================>.] - ETA: 0s - loss: 0.3195 - accuracy: 0.8626\n",
      "Epoch 00007: val_loss improved from 0.56838 to 0.49426, saving model to model/dogs_vs_cats-cnn-07-0.4943.hdf5\n",
      "20000/20000 [==============================] - 537s 27ms/sample - loss: 0.3201 - accuracy: 0.8625 - val_loss: 0.4943 - val_accuracy: 0.7638\n",
      "Epoch 8/10\n",
      "19968/20000 [============================>.] - ETA: 1s - loss: 0.2808 - accuracy: 0.8803\n",
      "Epoch 00008: val_loss did not improve from 0.49426\n",
      "20000/20000 [==============================] - 697s 35ms/sample - loss: 0.2806 - accuracy: 0.8804 - val_loss: 0.6187 - val_accuracy: 0.7270\n",
      "Epoch 9/10\n",
      "19968/20000 [============================>.] - ETA: 1s - loss: 0.2316 - accuracy: 0.9048\n",
      "Epoch 00009: val_loss did not improve from 0.49426\n",
      "20000/20000 [==============================] - 731s 37ms/sample - loss: 0.2313 - accuracy: 0.9050 - val_loss: 0.6294 - val_accuracy: 0.7158\n",
      "Epoch 10/10\n",
      "19968/20000 [============================>.] - ETA: 1:23 - loss: 0.1920 - accuracy: 0.9243\n",
      "Epoch 00010: val_loss did not improve from 0.49426\n",
      "20000/20000 [==============================] - 52380s 3s/sample - loss: 0.1920 - accuracy: 0.9243 - val_loss: 0.7873 - val_accuracy: 0.6702\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dbcb955b08>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## to save checkpoint to use latter\n",
    "model.fit(X, y, batch_size=BATCH_SIZE, epochs=N_EPOCH, validation_split=VALIDAION_SPLIT,\n",
    "          verbose=VERBOSE, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "del model\n",
    "model = load_model('model/dogs_vs_cats-cnn-07-0.4943.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 - 104s - loss: 0.3015 - accuracy: 0.8719\n",
      "MODEL ACCURACY: 0.87188\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X, y, verbose=2)\n",
    "print('MODEL ACCURACY: %.5f' % scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
