{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 베스트 모델 만들기 - 와인 사례\n",
    "## 이진 분류\n",
    "## 베스트 모델 업데이트하기 - 자동 중단, 그래프로 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 값 설정\n",
    "seed = 2020\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 입력\n",
    "df_pre = pd.read_csv('./dataset/wine.csv', header=None)\n",
    "df = df_pre.sample(frac=1)\n",
    "dataset = df.values\n",
    "X = dataset[:,0:12]\n",
    "Y = dataset[:,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 30)                390       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                372       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 875\n",
      "Trainable params: 875\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 설정\n",
    "model = Sequential([\n",
    "    Dense(30, input_dim=12, activation='relu'),\n",
    "    Dense(12, activation='relu'),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "]) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일 \n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 폴더 설정\n",
    "import os\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 조건 설정\n",
    "modelpath = MODEL_DIR + \"final{epoch:03d}-{val_loss:.4f}.hdf5\"\n",
    "\n",
    "checkpointer_callback = ModelCheckpoint(filepath=modelpath, monitor='val_loss', \n",
    "                               verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자동 중단 설정\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.18106, saving model to ./model/final001-2.1811.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.18106 to 1.25395, saving model to ./model/final002-1.2539.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.25395 to 0.56431, saving model to ./model/final003-0.5643.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.56431 to 0.41243, saving model to ./model/final004-0.4124.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.41243 to 0.36086, saving model to ./model/final005-0.3609.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.36086 to 0.30324, saving model to ./model/final006-0.3032.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.30324 to 0.27234, saving model to ./model/final007-0.2723.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.27234 to 0.25863, saving model to ./model/final008-0.2586.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.25863 to 0.25153, saving model to ./model/final009-0.2515.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.25153 to 0.24671, saving model to ./model/final010-0.2467.hdf5\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.24671 to 0.24256, saving model to ./model/final011-0.2426.hdf5\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.24256 to 0.23902, saving model to ./model/final012-0.2390.hdf5\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.23902 to 0.23558, saving model to ./model/final013-0.2356.hdf5\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.23558 to 0.23244, saving model to ./model/final014-0.2324.hdf5\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.23244 to 0.22943, saving model to ./model/final015-0.2294.hdf5\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.22943 to 0.22670, saving model to ./model/final016-0.2267.hdf5\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.22670 to 0.22474, saving model to ./model/final017-0.2247.hdf5\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.22474 to 0.22101, saving model to ./model/final018-0.2210.hdf5\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.22101 to 0.21803, saving model to ./model/final019-0.2180.hdf5\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.21803 to 0.21532, saving model to ./model/final020-0.2153.hdf5\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.21532 to 0.21278, saving model to ./model/final021-0.2128.hdf5\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.21278 to 0.21097, saving model to ./model/final022-0.2110.hdf5\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.21097 to 0.20804, saving model to ./model/final023-0.2080.hdf5\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.20804 to 0.20655, saving model to ./model/final024-0.2066.hdf5\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.20655 to 0.20374, saving model to ./model/final025-0.2037.hdf5\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.20374 to 0.20177, saving model to ./model/final026-0.2018.hdf5\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.20177 to 0.20116, saving model to ./model/final027-0.2012.hdf5\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.20116 to 0.19912, saving model to ./model/final028-0.1991.hdf5\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.19912 to 0.19720, saving model to ./model/final029-0.1972.hdf5\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.19720 to 0.19524, saving model to ./model/final030-0.1952.hdf5\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.19524 to 0.19330, saving model to ./model/final031-0.1933.hdf5\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.19330 to 0.19201, saving model to ./model/final032-0.1920.hdf5\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.19201 to 0.19005, saving model to ./model/final033-0.1900.hdf5\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.19005 to 0.18867, saving model to ./model/final034-0.1887.hdf5\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.18867\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.18867 to 0.18648, saving model to ./model/final036-0.1865.hdf5\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.18648 to 0.18462, saving model to ./model/final037-0.1846.hdf5\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.18462\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.18462 to 0.18407, saving model to ./model/final039-0.1841.hdf5\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.18407 to 0.18389, saving model to ./model/final040-0.1839.hdf5\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.18389 to 0.18002, saving model to ./model/final041-0.1800.hdf5\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.18002 to 0.17853, saving model to ./model/final042-0.1785.hdf5\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.17853 to 0.17737, saving model to ./model/final043-0.1774.hdf5\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.17737 to 0.17710, saving model to ./model/final044-0.1771.hdf5\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.17710 to 0.17662, saving model to ./model/final045-0.1766.hdf5\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.17662 to 0.17520, saving model to ./model/final046-0.1752.hdf5\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.17520 to 0.17347, saving model to ./model/final047-0.1735.hdf5\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.17347\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.17347 to 0.17182, saving model to ./model/final049-0.1718.hdf5\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.17182 to 0.17043, saving model to ./model/final050-0.1704.hdf5\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.17043 to 0.16909, saving model to ./model/final051-0.1691.hdf5\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.16909 to 0.16889, saving model to ./model/final052-0.1689.hdf5\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.16889 to 0.16698, saving model to ./model/final053-0.1670.hdf5\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.16698 to 0.16618, saving model to ./model/final054-0.1662.hdf5\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.16618 to 0.16548, saving model to ./model/final055-0.1655.hdf5\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.16548\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.16548 to 0.16310, saving model to ./model/final057-0.1631.hdf5\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.16310\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.16310 to 0.16088, saving model to ./model/final059-0.1609.hdf5\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.16088\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.16088\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.16088 to 0.15890, saving model to ./model/final062-0.1589.hdf5\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.15890 to 0.15830, saving model to ./model/final063-0.1583.hdf5\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.15830 to 0.15615, saving model to ./model/final064-0.1561.hdf5\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.15615\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.15615 to 0.15426, saving model to ./model/final066-0.1543.hdf5\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.15426 to 0.15306, saving model to ./model/final067-0.1531.hdf5\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.15306\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.15306 to 0.15142, saving model to ./model/final069-0.1514.hdf5\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.15142\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.15142\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.15142 to 0.14983, saving model to ./model/final072-0.1498.hdf5\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.14983\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.14983 to 0.14894, saving model to ./model/final074-0.1489.hdf5\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.14894 to 0.14642, saving model to ./model/final075-0.1464.hdf5\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.14642 to 0.14609, saving model to ./model/final076-0.1461.hdf5\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.14609 to 0.14457, saving model to ./model/final077-0.1446.hdf5\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.14457 to 0.14379, saving model to ./model/final078-0.1438.hdf5\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.14379 to 0.14314, saving model to ./model/final079-0.1431.hdf5\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.14314 to 0.14227, saving model to ./model/final080-0.1423.hdf5\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.14227 to 0.14090, saving model to ./model/final081-0.1409.hdf5\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.14090\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.14090\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.14090 to 0.13844, saving model to ./model/final084-0.1384.hdf5\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.13844\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.13844 to 0.13667, saving model to ./model/final086-0.1367.hdf5\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.13667 to 0.13592, saving model to ./model/final087-0.1359.hdf5\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.13592 to 0.13556, saving model to ./model/final088-0.1356.hdf5\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.13556 to 0.13509, saving model to ./model/final089-0.1351.hdf5\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.13509\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.13509\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.13509 to 0.13191, saving model to ./model/final092-0.1319.hdf5\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.13191\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.13191 to 0.13131, saving model to ./model/final094-0.1313.hdf5\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.13131 to 0.12946, saving model to ./model/final095-0.1295.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00096: val_loss did not improve from 0.12946\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.12946 to 0.12809, saving model to ./model/final097-0.1281.hdf5\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.12809 to 0.12764, saving model to ./model/final098-0.1276.hdf5\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.12764 to 0.12625, saving model to ./model/final099-0.1262.hdf5\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.12625 to 0.12534, saving model to ./model/final100-0.1253.hdf5\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.12534\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.12534 to 0.12476, saving model to ./model/final102-0.1248.hdf5\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.12476 to 0.12408, saving model to ./model/final103-0.1241.hdf5\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.12408 to 0.12369, saving model to ./model/final104-0.1237.hdf5\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.12369\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.12369 to 0.12090, saving model to ./model/final106-0.1209.hdf5\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.12090\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.12090 to 0.12030, saving model to ./model/final108-0.1203.hdf5\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.12030 to 0.11952, saving model to ./model/final109-0.1195.hdf5\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.11952 to 0.11821, saving model to ./model/final110-0.1182.hdf5\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.11821 to 0.11759, saving model to ./model/final111-0.1176.hdf5\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.11759 to 0.11723, saving model to ./model/final112-0.1172.hdf5\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.11723 to 0.11615, saving model to ./model/final113-0.1162.hdf5\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.11615 to 0.11523, saving model to ./model/final114-0.1152.hdf5\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.11523 to 0.11478, saving model to ./model/final115-0.1148.hdf5\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.11478 to 0.11435, saving model to ./model/final116-0.1144.hdf5\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.11435\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.11435 to 0.11401, saving model to ./model/final118-0.1140.hdf5\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.11401 to 0.11311, saving model to ./model/final119-0.1131.hdf5\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.11311 to 0.11150, saving model to ./model/final120-0.1115.hdf5\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.11150 to 0.11111, saving model to ./model/final121-0.1111.hdf5\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.11111 to 0.11020, saving model to ./model/final122-0.1102.hdf5\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.11020\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.11020\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.11020 to 0.10876, saving model to ./model/final125-0.1088.hdf5\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.10876\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.10876\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.10876\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.10876 to 0.10585, saving model to ./model/final129-0.1059.hdf5\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.10585\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.10585\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.10585\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.10585\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.10585 to 0.10444, saving model to ./model/final134-0.1044.hdf5\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.10444\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.10444 to 0.10165, saving model to ./model/final136-0.1017.hdf5\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.10165 to 0.10147, saving model to ./model/final137-0.1015.hdf5\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.10147 to 0.10033, saving model to ./model/final138-0.1003.hdf5\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.10033\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.10033\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.10033 to 0.09894, saving model to ./model/final141-0.0989.hdf5\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.09894\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.09894 to 0.09703, saving model to ./model/final143-0.0970.hdf5\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.09703\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.09703 to 0.09641, saving model to ./model/final145-0.0964.hdf5\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.09641\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.09641\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.09641\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.09641\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.09641\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.09641\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.09641\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.09641 to 0.09542, saving model to ./model/final153-0.0954.hdf5\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.09542 to 0.09285, saving model to ./model/final154-0.0928.hdf5\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.09285\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.09285 to 0.09160, saving model to ./model/final156-0.0916.hdf5\n",
      "\n",
      "Epoch 00157: val_loss improved from 0.09160 to 0.09036, saving model to ./model/final157-0.0904.hdf5\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.09036\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.09036\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.09036\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.09036\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.09036\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.09036\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.09036\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.09036 to 0.08800, saving model to ./model/final165-0.0880.hdf5\n",
      "\n",
      "Epoch 00166: val_loss improved from 0.08800 to 0.08706, saving model to ./model/final166-0.0871.hdf5\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.08706 to 0.08684, saving model to ./model/final167-0.0868.hdf5\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.08684\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.08684\n",
      "\n",
      "Epoch 00170: val_loss improved from 0.08684 to 0.08550, saving model to ./model/final170-0.0855.hdf5\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.08550\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.08550\n",
      "\n",
      "Epoch 00173: val_loss improved from 0.08550 to 0.08457, saving model to ./model/final173-0.0846.hdf5\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.08457\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.08457\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.08457\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.08457\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.08457\n",
      "\n",
      "Epoch 00179: val_loss improved from 0.08457 to 0.08448, saving model to ./model/final179-0.0845.hdf5\n",
      "\n",
      "Epoch 00180: val_loss improved from 0.08448 to 0.08352, saving model to ./model/final180-0.0835.hdf5\n",
      "\n",
      "Epoch 00181: val_loss improved from 0.08352 to 0.08257, saving model to ./model/final181-0.0826.hdf5\n",
      "\n",
      "Epoch 00182: val_loss improved from 0.08257 to 0.08111, saving model to ./model/final182-0.0811.hdf5\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.08111\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.08111\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.08111\n",
      "\n",
      "Epoch 00186: val_loss improved from 0.08111 to 0.08089, saving model to ./model/final186-0.0809.hdf5\n",
      "\n",
      "Epoch 00187: val_loss improved from 0.08089 to 0.07968, saving model to ./model/final187-0.0797.hdf5\n",
      "\n",
      "Epoch 00188: val_loss improved from 0.07968 to 0.07946, saving model to ./model/final188-0.0795.hdf5\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.07946\n",
      "\n",
      "Epoch 00190: val_loss improved from 0.07946 to 0.07914, saving model to ./model/final190-0.0791.hdf5\n",
      "\n",
      "Epoch 00191: val_loss improved from 0.07914 to 0.07856, saving model to ./model/final191-0.0786.hdf5\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.07856\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.07856\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.07856\n",
      "\n",
      "Epoch 00195: val_loss improved from 0.07856 to 0.07750, saving model to ./model/final195-0.0775.hdf5\n",
      "\n",
      "Epoch 00196: val_loss improved from 0.07750 to 0.07739, saving model to ./model/final196-0.0774.hdf5\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.07739\n",
      "\n",
      "Epoch 00198: val_loss improved from 0.07739 to 0.07720, saving model to ./model/final198-0.0772.hdf5\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.07720\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.07720\n",
      "\n",
      "Epoch 00201: val_loss improved from 0.07720 to 0.07651, saving model to ./model/final201-0.0765.hdf5\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.07651\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.07651\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.07651\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.07651\n",
      "\n",
      "Epoch 00206: val_loss improved from 0.07651 to 0.07536, saving model to ./model/final206-0.0754.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00207: val_loss did not improve from 0.07536\n",
      "\n",
      "Epoch 00208: val_loss improved from 0.07536 to 0.07515, saving model to ./model/final208-0.0752.hdf5\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.07515\n",
      "\n",
      "Epoch 00210: val_loss improved from 0.07515 to 0.07497, saving model to ./model/final210-0.0750.hdf5\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.07497\n",
      "\n",
      "Epoch 00212: val_loss improved from 0.07497 to 0.07379, saving model to ./model/final212-0.0738.hdf5\n",
      "\n",
      "Epoch 00213: val_loss improved from 0.07379 to 0.07323, saving model to ./model/final213-0.0732.hdf5\n",
      "\n",
      "Epoch 00214: val_loss improved from 0.07323 to 0.07313, saving model to ./model/final214-0.0731.hdf5\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.07313\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.07313\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.07313\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.07313\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.07313\n",
      "\n",
      "Epoch 00220: val_loss improved from 0.07313 to 0.07206, saving model to ./model/final220-0.0721.hdf5\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.07206\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.07206\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.07206\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.07206\n",
      "\n",
      "Epoch 00225: val_loss improved from 0.07206 to 0.07072, saving model to ./model/final225-0.0707.hdf5\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.07072\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.07072\n",
      "\n",
      "Epoch 00228: val_loss improved from 0.07072 to 0.07054, saving model to ./model/final228-0.0705.hdf5\n",
      "\n",
      "Epoch 00229: val_loss improved from 0.07054 to 0.07032, saving model to ./model/final229-0.0703.hdf5\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.07032\n",
      "\n",
      "Epoch 00231: val_loss improved from 0.07032 to 0.06994, saving model to ./model/final231-0.0699.hdf5\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.06994\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.06994\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.06994\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.06994\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.06994\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.06994\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.06994\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.06994\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.06994\n",
      "\n",
      "Epoch 00241: val_loss improved from 0.06994 to 0.06981, saving model to ./model/final241-0.0698.hdf5\n",
      "\n",
      "Epoch 00242: val_loss improved from 0.06981 to 0.06865, saving model to ./model/final242-0.0687.hdf5\n",
      "\n",
      "Epoch 00243: val_loss improved from 0.06865 to 0.06830, saving model to ./model/final243-0.0683.hdf5\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.06830\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.06830\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.06830\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.06830\n",
      "\n",
      "Epoch 00248: val_loss improved from 0.06830 to 0.06813, saving model to ./model/final248-0.0681.hdf5\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.06813\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.06813\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.06813\n",
      "\n",
      "Epoch 00252: val_loss improved from 0.06813 to 0.06786, saving model to ./model/final252-0.0679.hdf5\n",
      "\n",
      "Epoch 00253: val_loss improved from 0.06786 to 0.06696, saving model to ./model/final253-0.0670.hdf5\n",
      "\n",
      "Epoch 00254: val_loss improved from 0.06696 to 0.06690, saving model to ./model/final254-0.0669.hdf5\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.06690\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.06690\n",
      "\n",
      "Epoch 00257: val_loss improved from 0.06690 to 0.06672, saving model to ./model/final257-0.0667.hdf5\n",
      "\n",
      "Epoch 00258: val_loss improved from 0.06672 to 0.06616, saving model to ./model/final258-0.0662.hdf5\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.06616\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.06616\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.06616\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.06616\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.06616\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.06616\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.06616\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.06616\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.06616\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.06616\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.06616\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.06616\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.06616\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.06616\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.06616\n",
      "\n",
      "Epoch 00274: val_loss improved from 0.06616 to 0.06580, saving model to ./model/final274-0.0658.hdf5\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.06580\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.06580\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.06580\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.06580\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.06580\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.06580\n",
      "\n",
      "Epoch 00281: val_loss improved from 0.06580 to 0.06495, saving model to ./model/final281-0.0650.hdf5\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.06495\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.06495\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.06495\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.06495\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.06495\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.06495\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.06495\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.06495\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.06495\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.06495\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.06495\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.06495\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.06495\n",
      "\n",
      "Epoch 00295: val_loss improved from 0.06495 to 0.06397, saving model to ./model/final295-0.0640.hdf5\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.06397\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.06397\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.06397\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.06397\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.06397\n",
      "\n",
      "Epoch 00301: val_loss improved from 0.06397 to 0.06385, saving model to ./model/final301-0.0638.hdf5\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 0.06385\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 0.06385\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 0.06385\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 0.06385\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 0.06385\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 0.06385\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 0.06385\n",
      "\n",
      "Epoch 00309: val_loss improved from 0.06385 to 0.06381, saving model to ./model/final309-0.0638.hdf5\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 0.06381\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 0.06381\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 0.06381\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 0.06381\n",
      "\n",
      "Epoch 00314: val_loss improved from 0.06381 to 0.06347, saving model to ./model/final314-0.0635.hdf5\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 0.06347\n",
      "\n",
      "Epoch 00316: val_loss improved from 0.06347 to 0.06323, saving model to ./model/final316-0.0632.hdf5\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 0.06323\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 0.06323\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 0.06323\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 0.06323\n",
      "\n",
      "Epoch 00321: val_loss improved from 0.06323 to 0.06259, saving model to ./model/final321-0.0626.hdf5\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 0.06259\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 0.06259\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 0.06259\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 0.06259\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 0.06259\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 0.06259\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 0.06259\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 0.06259\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.06259\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 0.06259\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 0.06259\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 0.06259\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 0.06259\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 0.06259\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 0.06259\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 0.06259\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 0.06259\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 0.06259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00340: val_loss improved from 0.06259 to 0.06238, saving model to ./model/final340-0.0624.hdf5\n",
      "\n",
      "Epoch 00341: val_loss improved from 0.06238 to 0.06220, saving model to ./model/final341-0.0622.hdf5\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 0.06220\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 0.06220\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 0.06220\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 0.06220\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 0.06220\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 0.06220\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 0.06220\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 0.06220\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 0.06220\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 0.06220\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 0.06220\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 0.06220\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 0.06220\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 0.06220\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 0.06220\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 0.06220\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 0.06220\n",
      "\n",
      "Epoch 00359: val_loss improved from 0.06220 to 0.06174, saving model to ./model/final359-0.0617.hdf5\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 0.06174\n",
      "\n",
      "Epoch 00387: val_loss improved from 0.06174 to 0.06167, saving model to ./model/final387-0.0617.hdf5\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 0.06167\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 0.06167\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 0.06167\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 0.06167\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 0.06167\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 0.06167\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 0.06167\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 0.06167\n",
      "\n",
      "Epoch 00396: val_loss improved from 0.06167 to 0.06167, saving model to ./model/final396-0.0617.hdf5\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 0.06167\n",
      "\n",
      "Epoch 00398: val_loss improved from 0.06167 to 0.06151, saving model to ./model/final398-0.0615.hdf5\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 0.06151\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 0.06151\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 0.06151\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 0.06151\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 0.06151\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 0.06151\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 0.06151\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 0.06151\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 0.06151\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 0.06151\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 0.06151\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 0.06151\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 0.06151\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 0.06151\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 0.06151\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 0.06151\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 0.06151\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 0.06151\n",
      "\n",
      "Epoch 00417: val_loss improved from 0.06151 to 0.06124, saving model to ./model/final417-0.0612.hdf5\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 0.06124\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 0.06124\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 0.06124\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 0.06124\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 0.06124\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 0.06124\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 0.06124\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 0.06124\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 0.06124\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 0.06124\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 0.06124\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 0.06124\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 0.06124\n",
      "\n",
      "Epoch 00431: val_loss improved from 0.06124 to 0.06122, saving model to ./model/final431-0.0612.hdf5\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 0.06122\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 0.06122\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 0.06122\n",
      "\n",
      "Epoch 00435: val_loss improved from 0.06122 to 0.06116, saving model to ./model/final435-0.0612.hdf5\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 0.06116\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 0.06116\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 0.06116\n",
      "\n",
      "Epoch 00439: val_loss improved from 0.06116 to 0.06071, saving model to ./model/final439-0.0607.hdf5\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 0.06071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00499: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00501: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00502: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00503: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00504: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00505: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00506: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00507: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00508: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00509: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00510: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00511: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00512: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00513: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00514: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00515: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00516: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00517: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00518: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00519: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00520: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00521: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00522: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00523: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00524: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00525: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00526: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00527: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00528: val_loss did not improve from 0.06071\n",
      "\n",
      "Epoch 00529: val_loss improved from 0.06071 to 0.06064, saving model to ./model/final529-0.0606.hdf5\n",
      "\n",
      "Epoch 00530: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00531: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00532: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00533: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00534: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00535: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00536: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00537: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00538: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00539: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00540: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00541: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00542: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00543: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00544: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00545: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00546: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00547: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00548: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00549: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00550: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00551: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00552: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00553: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00554: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00555: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00556: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00557: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00558: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00559: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00560: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00561: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00562: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00563: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00564: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00565: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00566: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00567: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00568: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00569: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00570: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00571: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00572: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00573: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00574: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00575: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00576: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00577: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00578: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00579: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00580: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00581: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00582: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00583: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00584: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00585: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00586: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00587: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00588: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00589: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00590: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00591: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00592: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00593: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00594: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00595: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00596: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00597: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00598: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00599: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00600: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00601: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00602: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00603: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00604: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00605: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00606: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00607: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00608: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00609: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00610: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00611: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00612: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00613: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00614: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00615: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00616: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00617: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00618: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00619: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00620: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00621: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00622: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00623: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00624: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00625: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00626: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00627: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00628: val_loss did not improve from 0.06064\n",
      "\n",
      "Epoch 00629: val_loss did not improve from 0.06064\n"
     ]
    }
   ],
   "source": [
    "# 모델 실행 및 저장\n",
    "history = model.fit(X, Y, validation_split=0.33, epochs=3500, batch_size=500,\n",
    "                    verbose=0, callbacks=[early_stopping_callback, checkpointer_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6497/6497 - 0s - loss: 0.0483 - accuracy: 0.9886\n",
      "\n",
      " Accuracy: 0.9886\n"
     ]
    }
   ],
   "source": [
    "model = load_model('model/final529-0.0606.hdf5')\n",
    "print(\"\\n Accuracy: %.4f\" % (model.evaluate(X, Y, verbose=2)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_vloss에 테스트셋으로 실험 결과의 오차 값을 저장\n",
    "y_vloss=history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_acc에 학습셋으로 측정한 정확도의 값을 저장\n",
    "y_acc=history.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# x 값을 지정하고 정확도를 파란색으로, 오차를 빨간색으로 표시\n",
    "x_len = np.arange(len(y_acc))\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(x_len, y_vloss, \"o\", c=\"red\", markersize=2)\n",
    "plt.plot(x_len, y_acc, \"o\", c=\"blue\", markersize=2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
